{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.analysis\n",
    "from iris.cube import CubeList\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as mdates\n",
    "import geopandas as gpd\n",
    "import cf_units\n",
    "import cartopy.crs as ccrs\n",
    "import basic_info\n",
    "\n",
    "# Specify shapefile to work with\n",
    "shapefile = gpd.read_file(basic_info.shapefile_outline)\n",
    "location_name = basic_info.location_name\n",
    "\n",
    "# Creating a folder for outputs\n",
    "output_folder = f'{basic_info.directory_filepath}/outputs'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    with open('basic_info.py', 'a') as f:\n",
    "            f.write(f'\\noutput_folder = \"{output_folder}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "\n",
    "def add_season_year_dim(cube, seasons=None):\n",
    "    '''A function that returns a cube with the season_year attached as a\n",
    "    dimension\n",
    "\n",
    "    Input args:\n",
    "    ----------\n",
    "    cube  -- the cube to add the season_year to\n",
    "    '''\n",
    "    try:\n",
    "        cube.remove_coord('season_year')\n",
    "    except iris.exceptions.CoordinateNotFoundError:\n",
    "        pass\n",
    "    if seasons:\n",
    "        iris.coord_categorisation.add_season_year(cube, 'time', name='season_year',\n",
    "                                        seasons=seasons)\n",
    "    else:\n",
    "        iris.coord_categorisation.add_season_year(cube, 'time', name='season_year',\n",
    "                                        seasons=('djf','mam','jja','son')) # Define if different seasons are needed\n",
    "    return cube\n",
    "\n",
    "def add_season_dim(cube):\n",
    "    '''A function that returns a cube with the season attached as a\n",
    "    dimension\n",
    "\n",
    "    Input args:\n",
    "    ----------\n",
    "    cube  -- the cube to add the season to\n",
    "    '''\n",
    "    try:\n",
    "        cube.remove_coord('season')\n",
    "    except iris.exceptions.CoordinateNotFoundError:\n",
    "        pass\n",
    "    iris.coord_categorisation.add_season(cube, 'time', name='season',\n",
    "                                         seasons=('djf','mam','jja','son'))\n",
    "    return cube\n",
    "\n",
    "\n",
    "def add_day_of_month_dim(cube):\n",
    "    '''A function that returns a cube with the day of the month attached as a\n",
    "    dimension\n",
    "\n",
    "    Input args:\n",
    "    ----------\n",
    "    cube  -- the cube to add the day of the month to\n",
    "    '''\n",
    "    try:\n",
    "        cube.remove_coord('day_of_month')\n",
    "    except iris.exceptions.CoordinateNotFoundError:\n",
    "        pass\n",
    "    iris.coord_categorisation.add_day_of_month(cube, 'time', name='day_of_month')\n",
    "    return cube\n",
    "\n",
    "def add_day_of_year_dim(cube):\n",
    "    '''A function that returns a cube with the day of the year attached as a\n",
    "    dimension\n",
    "\n",
    "    Input args:\n",
    "    ----------\n",
    "    cube  -- the cube to add the day of the year to\n",
    "    '''\n",
    "    try:\n",
    "        cube.remove_coord('day_of_year')\n",
    "    except iris.exceptions.CoordinateNotFoundError:\n",
    "        pass\n",
    "    iris.coord_categorisation.add_day_of_year(cube, 'time', name='day_of_year')\n",
    "\n",
    "def add_month_dim(cube):\n",
    "    '''A function that returns a cube with the month attached as a\n",
    "    dimension\n",
    "\n",
    "    Input args:\n",
    "    ----------\n",
    "    cube  -- the cube to add the month to\n",
    "    '''\n",
    "    try:\n",
    "        cube.remove_coord('month')\n",
    "    except iris.exceptions.CoordinateNotFoundError:\n",
    "        pass\n",
    "    iris.coord_categorisation.add_month(cube, 'time', name='month')\n",
    "    return cube\n",
    "\n",
    "def add_hour_dim(cube):\n",
    "    '''A function that returns a cube with the hour attached as a\n",
    "    dimension\n",
    "\n",
    "    Input args:\n",
    "    ----------\n",
    "    cube  -- the cube to add the hour to\n",
    "    '''\n",
    "    try:\n",
    "        cube.remove_coord('hour')\n",
    "    except iris.exceptions.CoordinateNotFoundError:\n",
    "        pass\n",
    "    iris.coord_categorisation.add_hour(cube, 'time', name='hour')\n",
    "    return cube\n",
    "\n",
    "def hourly_to_daily_max(cube):\n",
    "    # Add day, month, and season year dimensions\n",
    "    add_day_month_season_year_dims(cube)\n",
    "    \n",
    "    # Aggregate by day of month, month, and season year\n",
    "    daily_max = cube.aggregated_by(['day_of_month', 'month', 'season_year'], iris.analysis.MAX)\n",
    "    \n",
    "    return daily_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_my_files():\n",
    "    heat_index_cube = iris.load_cube(basic_info.heat_index_cube)\n",
    "    print(f'Loaded Heat Index cube as heat_index_cube')\n",
    "\n",
    "    print('Adding useful information to the cube files')\n",
    "    heat_index_cube.convert_units('Kelvin')\n",
    "    add_day_of_year_dim(heat_index_cube)\n",
    "    add_season_year_dim(heat_index_cube)\n",
    "    add_month_dim(heat_index_cube)\n",
    "    \n",
    "    heat_index_cube.long_name = 'Lu and Romps Heat Index'\n",
    "\n",
    "    tas_cube = iris.load_cube(basic_info.tas_filepath)\n",
    "    print('Loaded tas cube')\n",
    "    rh_cube = iris.load_cube(basic_info.rh_filepath)\n",
    "    print('Loaded rh cube')\n",
    "\n",
    "    tas_cube.convert_units('Kelvin')\n",
    "\n",
    "    add_season_year_dim(tas_cube)\n",
    "    add_season_year_dim(rh_cube)\n",
    "    add_month_dim(tas_cube)\n",
    "    add_month_dim(rh_cube)\n",
    "    add_hour_dim(tas_cube)\n",
    "    add_hour_dim(rh_cube)\n",
    "    \n",
    "    return heat_index_cube, tas_cube, rh_cube\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_air_temperature_for_time_series_of_average_season_year_max_cell_values():\n",
    "    global tas_time_series_cube\n",
    "    tas_time_series_cube = tas_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    tas_time_series_cube = tas_time_series_cube.collapsed(['latitude','longitude'], iris.analysis.MEAN)\n",
    "    return tas_time_series_cube\n",
    "\n",
    "def collapse_air_temperature_for_maps_of_average_season_year_max_cell_values():\n",
    "    global tas_map_cube\n",
    "    tas_map_cube = tas_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    tas_map_cube = tas_cube.collapsed('time', iris.analysis.MEAN)\n",
    "    return tas_map_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_my_region():\n",
    "    fig, ax = plt.subplots()\n",
    "    shapefile.plot(ax=ax, facecolor='antiquewhite', edgecolor='black')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title(f'{location_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics_max_yearly(cube):\n",
    "    min_val = cube.aggregated_by('season_year', iris.analysis.MIN)\n",
    "    min_val = min_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "    lower_quartile = cube.aggregated_by('season_year', iris.analysis.PERCENTILE, percent=25)\n",
    "    lower_quartile = lower_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "    mean_val = cube.aggregated_by('season_year', iris.analysis.MEAN)\n",
    "    mean_val = mean_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "    median_val = cube.aggregated_by('season_year', iris.analysis.MEDIAN)\n",
    "    median_val = median_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "    upper_quartile = cube.aggregated_by('season_year', iris.analysis.PERCENTILE, percent=75)\n",
    "    upper_quartile = upper_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "    max_val = cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    max_val = max_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "    return min_val, lower_quartile, mean_val, median_val, upper_quartile, max_val\n",
    "\n",
    "def calculate_statistics_mean_yearly(cube):\n",
    "    min_val = cube.aggregated_by('season_year', iris.analysis.MIN)\n",
    "    min_val = min_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "    lower_quartile = cube.aggregated_by('season_year', iris.analysis.PERCENTILE, percent=25)\n",
    "    lower_quartile = lower_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "    mean_val = cube.aggregated_by('season_year', iris.analysis.MEAN)\n",
    "    mean_val = mean_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "    median_val = cube.aggregated_by('season_year', iris.analysis.MEDIAN)\n",
    "    median_val = median_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "    upper_quartile = cube.aggregated_by('season_year', iris.analysis.PERCENTILE, percent=75)\n",
    "    upper_quartile = upper_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "    max_val = cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    max_val = max_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "    return min_val, lower_quartile, mean_val, median_val, upper_quartile, max_val\n",
    "\n",
    "def calculate_statistics_max_monthly(cube):\n",
    "    min_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MIN)\n",
    "    min_val = min_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "    \n",
    "    lower_quartile = cube.aggregated_by(['season_year', 'month'], iris.analysis.PERCENTILE, percent=25)\n",
    "    lower_quartile = lower_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "    \n",
    "    mean_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MEAN)\n",
    "    mean_val = mean_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "    \n",
    "    median_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MEDIAN)\n",
    "    median_val = median_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "    \n",
    "    upper_quartile = cube.aggregated_by(['season_year', 'month'], iris.analysis.PERCENTILE, percent=75)\n",
    "    upper_quartile = upper_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "    \n",
    "    max_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MAX)\n",
    "    max_val = max_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "    \n",
    "    return min_val, lower_quartile, mean_val, median_val, upper_quartile, max_val\n",
    "\n",
    "def calculate_statistics_mean_monthly(cube):\n",
    "        min_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MIN)\n",
    "        min_val = min_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        lower_quartile = cube.aggregated_by(['season_year', 'month'], iris.analysis.PERCENTILE, percent=25)\n",
    "        lower_quartile = lower_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        mean_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MEAN)\n",
    "        mean_val = mean_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        median_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MEDIAN)\n",
    "        median_val = median_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        upper_quartile = cube.aggregated_by(['season_year', 'month'], iris.analysis.PERCENTILE, percent=75)\n",
    "        upper_quartile = upper_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        max_val = cube.aggregated_by(['season_year', 'month'], iris.analysis.MAX)\n",
    "        max_val = max_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        return min_val, lower_quartile, mean_val, median_val, upper_quartile, max_val\n",
    "\n",
    "def calculate_statistics_max_tas_and_rh(cube):\n",
    "        min_val = cube.aggregated_by('month', iris.analysis.MIN)\n",
    "        min_val = min_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "        lower_quartile = cube.aggregated_by(['season_year', 'month'], iris.analysis.PERCENTILE, percent=25)\n",
    "        lower_quartile = lower_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "        mean_val = cube.aggregated_by('month', iris.analysis.MEAN)\n",
    "        mean_val = mean_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "        median_val = cube.aggregated_by('month', iris.analysis.MEDIAN)\n",
    "        median_val = median_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "        upper_quartile = cube.aggregated_by('month', iris.analysis.PERCENTILE, percent=75)\n",
    "        upper_quartile = upper_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "        max_val = cube.aggregated_by('month', iris.analysis.MAX)\n",
    "        max_val = max_val.collapsed(['latitude', 'longitude'], iris.analysis.MAX).data\n",
    "\n",
    "        return min_val, lower_quartile, mean_val, median_val, upper_quartile, max_val\n",
    "\n",
    "def calculate_statistics_mean_tas_and_rh(cube):\n",
    "        min_val = cube.aggregated_by('month', iris.analysis.MIN)\n",
    "        min_val = min_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        lower_quartile = cube.aggregated_by('month', iris.analysis.PERCENTILE, percent=25)\n",
    "        lower_quartile = lower_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        mean_val = cube.aggregated_by('month', iris.analysis.MEAN)\n",
    "        mean_val = mean_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        median_val = cube.aggregated_by('month', iris.analysis.MEDIAN)\n",
    "        median_val = median_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        upper_quartile = cube.aggregated_by('month', iris.analysis.PERCENTILE, percent=75)\n",
    "        upper_quartile = upper_quartile.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        max_val = cube.aggregated_by('month', iris.analysis.MAX)\n",
    "        max_val = max_val.collapsed(['latitude', 'longitude'], iris.analysis.MEAN).data\n",
    "\n",
    "        return min_val, lower_quartile, mean_val, median_val, upper_quartile, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_tas_per_month():\n",
    "    mean_tas_over_space = tas_cube.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
    "    mean_tas_per_month = mean_tas_over_space.aggregated_by('month', iris.analysis.MEAN)\n",
    "    return mean_tas_per_month\n",
    "\n",
    "def calculate_mean_rh_per_month():\n",
    "    mean_rh_over_space = rh_cube.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
    "    mean_rh_per_month = mean_rh_over_space.aggregated_by('month', iris.analysis.MEAN)\n",
    "    return mean_rh_per_month\n",
    "\n",
    "def plot_monthly_average_tas_and_rh():\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "    axes=axes.flatten()\n",
    "    \n",
    "    months = np.unique(tas_cube.coord('month').points)\n",
    "    \n",
    "    tas_min, tas_lower_quartile, tas_mean, tas_median, tas_upper_quartile, tas_max = calculate_statistics_mean_tas_and_rh(tas_cube)\n",
    "    rh_min, rh_lower_quartile, rh_mean, rh_median, rh_upper_quartile, rh_max = calculate_statistics_mean_tas_and_rh(rh_cube)\n",
    "    \n",
    "    # Plot the average temperature per month\n",
    "    \n",
    "    axes[0].plot(months, tas_min, color='blue', label='Heat Min', linestyle ='-', marker='o')\n",
    "    axes[0].plot(months, tas_lower_quartile, color='green', label='Heat 25th Percentile', linestyle ='-', marker='v')\n",
    "    axes[0].plot(months, tas_mean, color='red', label='Heat Mean', linestyle ='-', marker='s')\n",
    "    axes[0].plot(months, tas_median, color='purple', label='Heat Median', linestyle ='-', marker='D')\n",
    "    axes[0].plot(months, tas_upper_quartile, color='orange', label='Heat 75th Percentile', linestyle ='-', marker='^')\n",
    "    axes[0].plot(months, tas_max, color='black', label='Heat Max', linestyle ='-', marker='x')\n",
    "\n",
    "    axes[0].set_xlabel('Month')\n",
    "    axes[0].set_ylabel('Temperature (K)')\n",
    "\n",
    "    axes[1].plot(months, rh_min, color='blue', label='Heat Min', linestyle ='-', marker='o')\n",
    "    axes[1].plot(months, rh_lower_quartile, color='green', label='Heat 25th Percentile', linestyle ='-', marker='v')\n",
    "    axes[1].plot(months, rh_mean, color='red', label='Heat Mean', linestyle ='-', marker='s')\n",
    "    axes[1].plot(months, rh_median, color='purple', label='Heat Median', linestyle ='-', marker='D')\n",
    "    axes[1].plot(months, rh_upper_quartile, color='orange', label='Heat 75th Percentile', linestyle ='-', marker='^')\n",
    "    axes[1].plot(months, rh_max, color='black', label='Heat Max', linestyle ='-', marker='x')\n",
    "\n",
    "    axes[1].set_xlabel('Month')\n",
    "    axes[1].set_ylabel('Humidity (%)')\n",
    "\n",
    "    handles, labels = axes[1].get_legend_handles_labels()\n",
    "    labels = ['Min', '25th Percentile', 'Mean', 'Median', '75th Percentile', 'Max'] # Updating the labels so they are only shown once\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=len(labels)/2, bbox_to_anchor=(0.5, -0.1)) # While loc already sets the legend to the centre, bbox_to_anchor's second value moves it down so it's not on top of the title\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.suptitle(f'Spatial Mean Air Temperature and Humidity per Month ({start_year}-{end_year})')\n",
    "    plt.savefig(f'{os.getcwd()}/outputs/average_air_temperature_and_humidity_per_month.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean average heat index per hour for the DJF season across space and time\n",
    "def calculate_mean_tas_per_hour():\n",
    "    mean_tas_per_hour = tas_cube.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
    "    mean_tas_per_hour = mean_tas_per_hour.aggregated_by('hour', iris.analysis.MEAN)\n",
    "    return mean_tas_per_hour\n",
    "\n",
    "def calculate_mean_rh_per_hour():\n",
    "    mean_rh_per_hour = rh_cube.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
    "    mean_rh_per_hour = mean_rh_per_hour.aggregated_by('hour', iris.analysis.MEAN)\n",
    "    return mean_rh_per_hour\n",
    "\n",
    "def plot_hourly_average_tas_and_rh():\n",
    "\n",
    "    # Create a dataframe of the mean temperature and humidity per hour to plot\n",
    "    mean_tas_per_hour = calculate_mean_tas_per_hour()\n",
    "    mean_rh_per_hour = calculate_mean_rh_per_hour()\n",
    "\n",
    "    mean_values_per_hour_dict = {'hour': mean_tas_per_hour.coord('hour').points,\n",
    "                                'mean_tas': mean_tas_per_hour.data,\n",
    "                                'mean_rh': mean_rh_per_hour.data}\n",
    "\n",
    "    mean_values_per_hour_df = pd.DataFrame(mean_values_per_hour_dict)\n",
    "    mean_values_per_hour_df = mean_values_per_hour_df.sort_values(by='hour').reset_index(drop=True)\n",
    "    mean_values_per_hour_df\n",
    "\n",
    "    fig = plt.figure(figsize=[10, 5])\n",
    "\n",
    "    ## Plot of the average temperature per hour\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(mean_values_per_hour_df['hour'], mean_values_per_hour_df['mean_tas'], label='tas', color='red', marker='o')\n",
    "\n",
    "    ax.set_xlabel('Hour')\n",
    "    ax.set_ylabel('Temperature (˚C)')\n",
    "    ax.set_xticks(np.arange(0, 24, 1))\n",
    "    ax.set_xlim(0, 23)\n",
    "    plt.title(f'Average Temperature per Hour ({start_year}-{end_year})')\n",
    "    plt.savefig(f'{output_folder}/{location_name}_average_temperature_per_hour.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plots\n",
    "    ## Plot of the average relative humidity per hour\n",
    "    fig = plt.figure(figsize=[10, 5])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(mean_values_per_hour_df['hour'], mean_values_per_hour_df['mean_rh'], label='rh', color='blue', marker='o')\n",
    "\n",
    "    ax.set_xlabel('Hour')\n",
    "    ax.set_ylabel('Relative Humidity (%)')\n",
    "    ax.set_xticks(np.arange(0, 24, 1))\n",
    "    ax.set_xlim(0, 23)\n",
    "    plt.title(f'Average Relative Humidity per Hour ({start_year}-{end_year})')\n",
    "    plt.savefig(f'{output_folder}/{location_name}_average_relative_humidity_per_hour.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    ## Combined plot per hour\n",
    "    fig, ax_temp = plt.subplots()\n",
    "    ax_temp.plot(mean_values_per_hour_df['hour'], mean_values_per_hour_df['mean_tas'], label='Temperature', color='red', marker='o')\n",
    "\n",
    "    ax_temp.set_xticks(np.arange(0, 24, 1))\n",
    "    ax_temp.set_xlim(0, 23)\n",
    "\n",
    "    ax_temp.set_xlabel('Hour')\n",
    "    ### Set labels for primary axis\n",
    "    ax_temp.set_ylabel('Temperature (˚C)', color='red')\n",
    "    ax_temp.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "    ### Create secondary axis for humidity\n",
    "    ax_hum = ax_temp.twinx()\n",
    "    ax_hum.plot(mean_values_per_hour_df['hour'], mean_values_per_hour_df['mean_rh'],label='Humidity', color='blue', marker='o')\n",
    "\n",
    "    ### Set labels for secondary axis\n",
    "    ax_hum.set_ylabel('Humidity (%)', color='blue')\n",
    "    ax_hum.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    ### Title\n",
    "    plt.title(f'Average Temperature and Humidity per Hour ({start_year}-{end_year})')\n",
    "\n",
    "    ### Save and show plot\n",
    "    plt.savefig(f'{output_folder}/{location_name}_average_temperature_and_humidity_per_hour.png')\n",
    "    plt.show()\n",
    "\n",
    "    return mean_tas_per_hour, mean_rh_per_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction: adjust the below to show variables you are interested in.\n",
    "def create_season_year_aggregates():\n",
    "    global tas_cube_yearly_mean, rh_cube_yearly_mean, tas_cube_yearly_min, rh_cube_yearly_min, tas_cube_yearly_max, rh_cube_yearly_max\n",
    "    \n",
    "    tas_cube_yearly_mean = tas_cube.aggregated_by('season_year', iris.analysis.MEAN)\n",
    "    tas_cube_yearly_mean = tas_cube_yearly_mean.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
    "    rh_cube_yearly_mean = rh_cube.aggregated_by('season_year', iris.analysis.MEAN)\n",
    "    rh_cube_yearly_mean = rh_cube_yearly_mean.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
    "\n",
    "    # Min cubes\n",
    "    tas_cube_yearly_min = tas_cube.aggregated_by('season_year', iris.analysis.MIN)\n",
    "    tas_cube_yearly_min = tas_cube_yearly_min.collapsed(['latitude', 'longitude'], iris.analysis.MIN)\n",
    "    rh_cube_yearly_min = rh_cube.aggregated_by('season_year', iris.analysis.MIN)\n",
    "    rh_cube_yearly_min = rh_cube_yearly_min.collapsed(['latitude', 'longitude'], iris.analysis.MIN)\n",
    "\n",
    "    # Max cubes\n",
    "    tas_cube_yearly_max = tas_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    tas_cube_yearly_max = tas_cube_yearly_max.collapsed(['latitude', 'longitude'], iris.analysis.MAX)\n",
    "    rh_cube_yearly_max = rh_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    rh_cube_yearly_max = rh_cube_yearly_max.collapsed(['latitude', 'longitude'], iris.analysis.MAX)\n",
    "\n",
    "def create_overall_aggregates():\n",
    "    global tas_cube_overall_mean, rh_cube_overall_mean, tas_cube_overall_min, rh_cube_overall_min, tas_cube_overall_max, rh_cube_overall_max\n",
    "# Calculating the OVERALL () mean, min, and max for each variable\n",
    "    # Mean cubes\n",
    "    tas_cube_overall_mean = tas_cube.aggregated_by('season_year', iris.analysis.MEAN)\n",
    "    tas_cube_overall_mean = tas_cube_overall_mean.collapsed('time', iris.analysis.MEAN)\n",
    "    rh_cube_overall_mean = rh_cube.aggregated_by('season_year', iris.analysis.MEAN)\n",
    "    rh_cube_overall_mean = rh_cube_overall_mean.collapsed('time', iris.analysis.MEAN)\n",
    "\n",
    "    # Min cubes\n",
    "    tas_cube_overall_min = tas_cube.aggregated_by('season_year', iris.analysis.MIN)\n",
    "    tas_cube_overall_min = tas_cube_overall_min.collapsed('time', iris.analysis.MIN)\n",
    "    rh_cube_overall_min = rh_cube.aggregated_by('season_year', iris.analysis.MIN)\n",
    "    rh_cube_overall_min = rh_cube_overall_min.collapsed('time', iris.analysis.MIN)\n",
    "\n",
    "    # Max cubes\n",
    "    tas_cube_overall_max = tas_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    tas_cube_overall_max = tas_cube_overall_max.collapsed('time', iris.analysis.MAX)\n",
    "    rh_cube_overall_max = rh_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    rh_cube_overall_max = rh_cube_overall_max.collapsed('time', iris.analysis.MAX)\n",
    "\n",
    "def plot_min_mean_max_analysis_maps():\n",
    "    fig = plt.figure(figsize=(17, 19))\n",
    "    fig.subplots_adjust(left=0.2)  # Adjust the left padding to increase space for y-labels and titles\n",
    "    subfigs = fig.subfigures(3, 1)\n",
    "    \n",
    "    subfigs[0].suptitle('Min', x=0.05, y=0.6, ha='left', va='center', fontsize=14, rotation=90)\n",
    "    subfigs[1].suptitle('Mean', x=0.05, y=0.6, ha='left', va='center', fontsize=14, rotation=90)\n",
    "    subfigs[2].suptitle('Max', x=0.05, y=0.6, ha='left', va='center', fontsize=14, rotation=90)\n",
    "\n",
    "    axstop = subfigs[0].subplots(1, 2, sharex=True, sharey=True)\n",
    "    axsmid = subfigs[1].subplots(1, 2, sharex=True, sharey=True)\n",
    "    axsbott = subfigs[2].subplots(1, 2, sharex=True, sharey=True)\n",
    "\n",
    "    longitude = tas_cube_overall_mean.coord('longitude').points\n",
    "    latitude = tas_cube_overall_mean.coord('latitude').points\n",
    "    lon, lat = np.meshgrid(longitude, latitude)  # Create a meshgrid for plotting\n",
    "\n",
    "    # Plot 1: Yearly summer min temperature at surface\n",
    "    mesh1 = axstop[0].pcolormesh(lon, lat, tas_cube_overall_min.data, cmap='Reds')\n",
    "    cbar1 = fig.colorbar(mesh1, ax=axstop[0], orientation='horizontal')\n",
    "    cbar1.set_ticks(np.linspace(tas_cube_overall_min.data.min(), tas_cube_overall_min.data.max(), 5))\n",
    "    cbar1.ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))  # Format ticks to 1 decimal place\n",
    "    axstop[0].set_xlabel('Longitude')\n",
    "    axstop[0].set_ylabel('Latitude')\n",
    "\n",
    "    shapefile.plot(ax=axstop[0], color='none', edgecolor='black', linewidth=1)  # Overlay the shape file on the first plot\n",
    "    axstop[0].set_title(f'Temperature at Surface \\n', fontsize=14)\n",
    "\n",
    "    # Plot 2: Yearly summer mean humidity\n",
    "    mesh2 = axstop[1].pcolormesh(lon, lat, rh_cube_overall_min.data, cmap='Blues')\n",
    "    cbar2 = fig.colorbar(mesh2, ax=axstop[1], orientation='horizontal')\n",
    "    cbar2.set_ticks(np.linspace(rh_cube_overall_min.data.min(), rh_cube_overall_min.data.max(), 5))\n",
    "    cbar2.ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))  # Format ticks to 1 decimal place\n",
    "    axstop[1].set_xlabel('Longitude')\n",
    "    axstop[1].set_ylabel('Latitude')\n",
    "\n",
    "    shapefile.plot(ax=axstop[1], color='none', edgecolor='black', linewidth=1)  # Overlay the shape file on the first plot\n",
    "    axstop[1].set_title(f'Humidity (%) \\n', fontsize=14)\n",
    "\n",
    "    # Plot 3: Yearly summer mean temperature at surface\n",
    "    mesh3 = axsmid[0].pcolormesh(lon, lat, tas_cube_overall_mean.data, cmap='Reds')\n",
    "    cbar3 = fig.colorbar(mesh3, ax=axsmid[0], orientation='horizontal')\n",
    "    cbar3.set_ticks(np.linspace(tas_cube_overall_mean.data.min(), tas_cube_overall_mean.data.max(), 5))\n",
    "    cbar3.ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))  # Format ticks to 1 decimal place\n",
    "    axsmid[0].set_xlabel('Longitude')\n",
    "    axsmid[0].set_ylabel('Latitude')\n",
    "\n",
    "    shapefile.plot(ax=axsmid[0], color='none', edgecolor='black', linewidth=1)  # Overlay the shape file on the first plot\n",
    "\n",
    "    # Plot 4: Yearly summer mean humidity\n",
    "    mesh4 = axsmid[1].pcolormesh(lon, lat, rh_cube_overall_mean.data, cmap='Blues')\n",
    "    cbar4 = fig.colorbar(mesh4, ax=axsmid[1], orientation='horizontal')\n",
    "    cbar4.set_ticks(np.linspace(rh_cube_overall_mean.data.min(), rh_cube_overall_mean.data.max(), 5))\n",
    "    cbar4.ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))  # Format ticks to 1 decimal place\n",
    "    axsmid[1].set_xlabel('Longitude')\n",
    "    axsmid[1].set_ylabel('Latitude')\n",
    "\n",
    "    shapefile.plot(ax=axsmid[1], color='none', edgecolor='black', linewidth=1)  # Overlay the shape file on the first plot\n",
    "\n",
    "    # Plot 5: Yearly summer max temperature at surface\n",
    "    mesh5 = axsbott[0].pcolormesh(lon, lat, tas_cube_overall_max.data, cmap='Reds')\n",
    "    cbar5 = fig.colorbar(mesh5, ax=axsbott[0], orientation='horizontal')\n",
    "    cbar5.set_ticks(np.linspace(tas_cube_overall_max.data.min(), tas_cube_overall_max.data.max(), 5))\n",
    "    cbar5.ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))  # Format ticks to 1 decimal place\n",
    "    axsbott[0].set_xlabel('Longitude')\n",
    "    axsbott[0].set_ylabel('Latitude')\n",
    "    shapefile.plot(ax=axsbott[0], color='none', edgecolor='black', linewidth=1)  # Overlay the shape file on the first plot\n",
    "\n",
    "    # Plot 6: Yearly summer max humidity\n",
    "    mesh6 = axsbott[1].pcolormesh(lon, lat, rh_cube_overall_max.data, cmap='Blues')\n",
    "    cbar6 = fig.colorbar(mesh6, ax=axsbott[1], orientation='horizontal')\n",
    "    cbar6.set_ticks(np.linspace(rh_cube_overall_max.data.min(), rh_cube_overall_max.data.max(), 5))\n",
    "    cbar6.ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))  # Format ticks to 1 decimal place\n",
    "    axsbott[1].set_xlabel('Longitude')\n",
    "    axsbott[1].set_ylabel('Latitude')\n",
    "    shapefile.plot(ax=axsbott[1], color='none', edgecolor='black', linewidth=1)  # Overlay the shape file on the first plot\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(f'{output_folder}/{location_name}_analysis_maps.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporally_plot_monthly_mean_values_from_Lu_and_Romps_against_air_temperature():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Calculate min, lower quartile, mean, median, upper quartile, and max for the heat_index_cube and tas_cube\n",
    "    heat_min, heat_lower_quartile, heat_mean, heat_median, heat_upper_quartile, heat_max = calculate_statistics_max_yearly(heat_index_cube)\n",
    "    tas_min, tas_lower_quartile, tas_mean, tas_median, tas_upper_quartile, tas_max = calculate_statistics_max_yearly(tas_cube)  \n",
    "\n",
    "\n",
    "    # Creating \"aggregated_cube\" so I can use it across all time plots to draw coordinates from without having to specify a new file each time (gets confusing otherwise)\n",
    "    aggregated_cube = heat_index_cube.aggregated_by('season_year', iris.analysis.MIN)\n",
    "    aggregated_cube = aggregated_cube.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
    "\n",
    "    time_points = aggregated_cube.coord('time').points\n",
    "    time_unit = aggregated_cube.coord('time').units\n",
    "\n",
    "    # Convert numerical time points to actually readable dates\n",
    "    readable_dates = cf_units.num2date(time_points, time_unit.origin, time_unit.calendar)\n",
    "    formatted_dates = [date.strftime('%Y-%m') for date in readable_dates]\n",
    "\n",
    "    # Plot the data with improved styling\n",
    "    ax.plot(formatted_dates, heat_max, color='black', label='Heat Max', linestyle ='-', marker='x')\n",
    "    ax.plot(formatted_dates, heat_upper_quartile, color='orange', label='Heat 75th Percentile', linestyle ='-', marker='^')\n",
    "    ax.plot(formatted_dates, heat_median, color='purple', label='Heat Median', linestyle ='-', marker='D')\n",
    "    ax.plot(formatted_dates, heat_mean, color='red', label='Heat Mean', linestyle ='-', marker='s')\n",
    "    ax.plot(formatted_dates, heat_lower_quartile, color='green', label='Heat 25th Percentile', linestyle ='-', marker='v')\n",
    "    ax.plot(formatted_dates, heat_min, color='blue', label='Heat Min', linestyle ='-', marker='o')    \n",
    "    \n",
    "    #ax.plot(formatted_dates, tas_max, color='grey', label='Tas Max', linestyle='--', marker='x')\n",
    "    #ax.plot(formatted_dates, tas_upper_quartile, color='brown', label='Tas 75th Percentile', linestyle='--', marker='^')\n",
    "    #ax.plot(formatted_dates, tas_median, color='yellow', label='Tas Median', linestyle='--', marker='D')\n",
    "    #ax.plot(formatted_dates, tas_mean, color='magenta', label='Tas Mean', linestyle='--', marker='s')\n",
    "    #ax.plot(formatted_dates, tas_lower_quartile, color='lime', label='Tas 25th Percentile', linestyle='--', marker='v')\n",
    "    #ax.plot(formatted_dates, tas_min, color='cyan', label='Tas Min', linestyle='--', marker='o')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Mean Value (K)')\n",
    "    ax.set_title(\"Yearly Mean Values from Lu and Romps' (2022) Heat Index\")\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.grid(True)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Reduces the number of x-axis ticks\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(10))  # Shows ticks and labels every 20 years\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) # Shows tick labels only as years. Change this to '%Y-%m' if you want to see the month as well but will likely look overcrowded with many years of data input\n",
    "    plt.setp(ax.get_xticklabels(), ha='center')\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/yearly_temporal_mean_values_from_Lu_and_Romps.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maximum_values_per_cell(heat_index_cube):\n",
    "    heat_index_cube = heat_index_cube.copy()\n",
    "    heat_index_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    heat_index_cube.collapsed('time', iris.analysis.MAX)\n",
    "    return heat_index_cube\n",
    "\n",
    "def find_maximum_values_per_cell_for_tas(tas_cube):\n",
    "    tas_cube_maximums = tas_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    tas_cube_maximums = tas_cube_maximums.collapsed('time', iris.analysis.MAX)\n",
    "    return tas_cube_maximums\n",
    "\n",
    "def find_temporal_average_maximum_values_per_cell():\n",
    "\n",
    "    heat_index_cube.aggregated_by('season_year', iris.analysis.MAX)\n",
    "    heat_index_cube.collapsed('time', iris.analysis.MEAN)\n",
    "    return heat_index_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics_per_decade(cube):\n",
    "    decades = range(1951, 1994, 10)\n",
    "    statistics = {}\n",
    "\n",
    "    for start_year in decades:\n",
    "        end_year = start_year + 9\n",
    "        decade_cube = cube.extract(iris.Constraint(time=lambda cell: start_year <= cell.point.year <= end_year))\n",
    "        \n",
    "        min_val = decade_cube.collapsed('time', iris.analysis.MIN)\n",
    "        # lower_quartile = decade_cube.collapsed('time', iris.analysis.PERCENTILE, percent=25)\n",
    "        mean_val = decade_cube.collapsed('time', iris.analysis.MEAN)\n",
    "        # median_val = decade_cube.collapsed('time', iris.analysis.MEDIAN)\n",
    "        # upper_quartile = decade_cube.collapsed('time', iris.analysis.PERCENTILE, percent=75)\n",
    "        max_val = decade_cube.collapsed('time', iris.analysis.MAX)\n",
    "        \n",
    "        statistics[start_year] = {\n",
    "            'min': min_val,\n",
    "            #'lower_quartile': lower_quartile,\n",
    "            'mean': mean_val,\n",
    "            #'median': median_val,\n",
    "            #'upper_quartile': upper_quartile,\n",
    "            'max': max_val\n",
    "        }\n",
    "    \n",
    "    return statistics\n",
    "\n",
    "def plot_decadal_maps(statistics, output_folder):\n",
    "    metrics = ['min', \n",
    "               #'lower_quartile',\n",
    "               'mean', \n",
    "               #'median', \n",
    "               #'upper_quartile', \n",
    "               'max']\n",
    "    decades = sorted(statistics.keys())\n",
    "    \n",
    "    # Adjust ncols to exclude the final column (otherwise includes a decade after 1990)\n",
    "    fig, axes = plt.subplots(nrows=len(metrics), ncols=len(decades) - 1, figsize=(18, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, start_year in enumerate(decades[:-1]):  # Exclude the last decade\n",
    "            ax = axes[i, j]\n",
    "            if i == 0:  # Needed to change the titles of the subplots to be just at the top of the first row\n",
    "                ax.set_title(f'{start_year} - {start_year + 9}')\n",
    "            ax.set_ylabel(metric.capitalize())\n",
    "            \n",
    "            cube = statistics[start_year][metric]\n",
    "            mesh = ax.pcolormesh(cube.coord('longitude').points, cube.coord('latitude').points, cube.data, cmap='Reds')\n",
    "            fig.colorbar(mesh, ax=ax, orientation='horizontal', pad=0.02)\n",
    "            shapefile.plot(ax=ax, edgecolor='black', facecolor='none')\n",
    "\n",
    "    # Add row labels using fig.text for better control\n",
    "    row_labels = metrics\n",
    "    for row, label in enumerate(row_labels):\n",
    "        fig.text(0.05, 0.79 - row * 0.31, label.capitalize(), va='center', ha='center', rotation='vertical', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout(rect=[0.05, 0.01, 1, 0.95])  # Adjust the left margin to make space for the labels, otherwise overlaps\n",
    "    plt.savefig(f'{output_folder}/decadal_heat_index_maps.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map_for_lu_and_romps_average_maximum_cell_values():\n",
    "    cube = lu_and_romps_average_maximum_cell_values\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Adjust figsize as needed\n",
    "    fig.suptitle('Heat Index Map: Spatial Distribution of Mean Values for Max Season Year')\n",
    "\n",
    "    longitude = cube.coord('longitude').points\n",
    "    latitude = cube.coord('latitude').points\n",
    "    lon, lat = np.meshgrid(longitude, latitude)\n",
    "\n",
    "    data_min = cube.data.min()\n",
    "    data_max = cube.data.max()\n",
    "    \n",
    "    # Determine the appropriate colormap and normalization\n",
    "    if data_max <= 0:\n",
    "        cmap = 'Blues'\n",
    "        norm = mcolors.Normalize(vmin=data_min, vmax=0)\n",
    "        ticks = np.linspace(data_min, 0, 5)\n",
    "    elif data_min > 0:\n",
    "        cmap = 'Reds'\n",
    "        norm = mcolors.Normalize(vmin=data_min, vmax=data_max)\n",
    "        ticks = np.linspace(data_min, data_max, 5)\n",
    "    else: # If the data crosses zero \n",
    "        vmin = min(data_min, 0)\n",
    "        vmax = max(data_max, 0)\n",
    "        vcenter = (vmin + vmax) / 2\n",
    "        cmap = 'bwr'\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "        ticks = np.linspace(data_min, data_max, 5)\n",
    "    \n",
    "    mesh = ax.pcolormesh(lon, lat, cube.data, cmap=cmap, norm=norm, shading='auto')\n",
    "    cbar = fig.colorbar(mesh, ax=ax, orientation='horizontal')\n",
    "    \n",
    "    # Set colorbar ticks and labels\n",
    "    cbar.set_ticks(ticks)\n",
    "    cbar.set_ticklabels([f'{val:.2f}' for val in ticks])\n",
    "\n",
    "    ax.set_title('Lu and Romps Average Maximum Cell Values')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "    shapefile.plot(ax=ax, color='none', edgecolor='black', linewidth=1)\n",
    "\n",
    "    output_folder = f\"outputs/heat_index_outputs\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "    \n",
    "    plt.savefig(f'{output_folder}/lu_and_romps_average_maximum_cell_values_map.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporally_plot_monthly_max_values_from_Lu_and_Romps_against_air_temperature():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Calculate min, lower quartile, mean, median, upper quartile, and max for the heat_index_cube and tas_cube\n",
    "    heat_min, heat_lower_quartile, heat_mean, heat_median, heat_upper_quartile, heat_max = calculate_statistics_max_yearly(heat_index_cube)\n",
    "    tas_min, tas_lower_quartile, tas_mean, tas_median, tas_upper_quartile, tas_max = calculate_statistics_max_yearly(tas_cube)\n",
    "\n",
    "    # Assuming `aggregated_cube` is already defined\n",
    "    time_points = aggregated_cube.coord('time').points\n",
    "    time_unit = aggregated_cube.coord('time').units\n",
    "\n",
    "    # Convert numerical time points to human-readable dates\n",
    "    readable_dates = cf_units.num2date(time_points, time_unit.origin, time_unit.calendar)\n",
    "    formatted_dates = [date.strftime('%Y-%m') for date in readable_dates]\n",
    "\n",
    "    # Plot the data with improved styling\n",
    "    ax.plot(formatted_dates, heat_min, color='blue', label='HI Min', marker='o')\n",
    "    ax.plot(formatted_dates, heat_lower_quartile, color='green', label='HI 25th Percentile', marker='v')\n",
    "    ax.plot(formatted_dates, heat_mean, color='red', label='HI Mean', marker='s')\n",
    "    ax.plot(formatted_dates, heat_median, color='purple', label='HI Median', marker='D')\n",
    "    ax.plot(formatted_dates, heat_upper_quartile, color='orange', label='HI 75th Percentile', marker='^')\n",
    "    ax.plot(formatted_dates, heat_max, color='black', label='HI Max', marker='x')\n",
    "\n",
    "    ax.plot(formatted_dates, tas_min, color='cyan', label='AT Min', linestyle='--', marker='o')\n",
    "    ax.plot(formatted_dates, tas_lower_quartile, color='lime', label='AT 25th Percentile', linestyle='--', marker='v')\n",
    "    ax.plot(formatted_dates, tas_mean, color='magenta', label='AT Mean', linestyle='--', marker='s')\n",
    "    ax.plot(formatted_dates, tas_median, color='yellow', label='AT Median', linestyle='--', marker='D')\n",
    "    ax.plot(formatted_dates, tas_upper_quartile, color='brown', label='AT 75th Percentile', linestyle='--', marker='^')\n",
    "    ax.plot(formatted_dates, tas_max, color='grey', label='AT Max', linestyle='--', marker='x')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Max Value (K)')\n",
    "    ax.set_title(\"Yearly Max Values from Lu and Romps' (2022) Heat Index and Air Temperature\")\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.grid(True)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Reduces the number of x-axis ticks\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(20))  # Shows ticks and labels every 20 years\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) # Shows tick labels only as years. Change this to '%Y-%m' if you want to see the month as well but will likely look overcrowded with many years of data input\n",
    "    plt.setp(ax.get_xticklabels(), ha='center')\n",
    "    \n",
    "    # Save and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/yearly_temporal_max_values_from_Lu_and_Romps_against_air_temperature.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference_between_lu_and_romps_and_air_temperature():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Extract years and months\n",
    "    years = np.unique(heat_index_cube.coord('season_year').points)\n",
    "    months = np.unique(heat_index_cube.coord('month').points)\n",
    "\n",
    "    # Calculate statistics for Lu and Romps heat index and air temperature\n",
    "    heat_min, heat_lower_quartile, heat_mean, heat_median, heat_upper_quartile, heat_max = calculate_statistics_max_yearly(heat_index_cube)\n",
    "    tas_min, tas_lower_quartile, tas_mean, tas_median, tas_upper_quartile, tas_max = calculate_statistics_max_yearly(tas_cube)\n",
    "\n",
    "    # Assuming `aggregated_cube` is already defined\n",
    "    time_points = aggregated_cube.coord('time').points\n",
    "    time_unit = aggregated_cube.coord('time').units\n",
    "\n",
    "    # Convert numerical time points to human-readable dates\n",
    "    readable_dates = cf_units.num2date(time_points, time_unit.origin, time_unit.calendar)\n",
    "    formatted_dates = [date.strftime('%Y-%m') for date in readable_dates]\n",
    "\n",
    "    # Calculate differences\n",
    "    diff_min = heat_min - tas_min\n",
    "    diff_lower_quartile = heat_lower_quartile - tas_lower_quartile\n",
    "    diff_mean = heat_mean - tas_mean\n",
    "    diff_median = heat_median - tas_median\n",
    "    diff_upper_quartile = heat_upper_quartile - tas_upper_quartile\n",
    "    diff_max = heat_max - tas_max\n",
    "\n",
    "    # Plot the differences\n",
    "    ax.plot(formatted_dates, diff_min, color='blue', label='Min Difference', marker='o')\n",
    "    ax.plot(formatted_dates, diff_lower_quartile, color='green', label='25th Percentile Difference', marker='v')\n",
    "    ax.plot(formatted_dates, diff_mean, color='red', label='Mean Difference', marker='s')\n",
    "    ax.plot(formatted_dates, diff_median, color='purple', label='Median Difference', marker='D')\n",
    "    ax.plot(formatted_dates, diff_upper_quartile, color='orange', label='75th Percentile Difference', marker='^')\n",
    "    ax.plot(formatted_dates, diff_max, color='black', label='Max Difference', marker='x')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Temperature Difference (K)')\n",
    "    ax.set_title(\"Differences Between Yearly Max Values from Lu and Romps' (2022) Heat Index and Air Temperature\")\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlim(formatted_dates[0], formatted_dates[-1])\n",
    "\n",
    "    # Reduces the number of x-axis ticks\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(20))  # Shows ticks and labels every 20 years\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) # Shows tick labels only as years. Change this to '%Y-%m' if you want to see the month as well but will likely look overcrowded with many years of data input\n",
    "    plt.setp(ax.get_xticklabels(), ha='center')\n",
    "    \n",
    "    # Save and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/differences_between_yearly_temporal_max_values_from_Lu_and_Romps_against_air_temperature.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
